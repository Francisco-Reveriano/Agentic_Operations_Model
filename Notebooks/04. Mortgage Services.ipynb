{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-09T17:41:54.462586Z",
     "start_time": "2025-08-09T17:41:39.261984Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from agents import Runner, agent, trace, set_trace_processors, Agent, ModelSettings\n",
    "from weave.integrations.openai_agents.openai_agents import WeaveTracingProcessor\n",
    "import asyncio\n",
    "from typing import Literal, List, Annotated\n",
    "import weave\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field, conlist\n",
    "from IPython.display import display, Markdown, HTML, Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "load_dotenv()\n",
    "# Import Necessary Libraries\n",
    "from src.Agents.Master_Agent import q_a_agent\n",
    "# Import Weave and Biases\n",
    "weave.init(\"Operation Model\")\n",
    "set_trace_processors([WeaveTracingProcessor()])\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m\u001B[1mweave\u001B[0m: Logged in as Weights & Biases user: francisco-reveriano-1.\n",
      "\u001B[36m\u001B[1mweave\u001B[0m: View Weave data at https://wandb.ai/francisco-reveriano-1-mckinsey-company/operation-model/weave\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Single Query",
   "id": "c830d0d78c509b51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with trace(\"Test Query\"):\n",
    "    message = \"What is the 5-year cumulative percentage change that Generative AI will have on the following process: Quality Improvement & Reporting within the following Line of Business (LoB): Mortgage Servicing? Keep in mind that the bank's current onshore capacity is 60.0 Full-Time Equivalent Employees.\"\n",
    "    response = await Runner.run(q_a_agent, message, max_turns=100)\n",
    "\n",
    "print(response.final_output)"
   ],
   "id": "f3613220eb178ee7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "response.final_output.use_online_coursework",
   "id": "645872c5f54b0127",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Dataset",
   "id": "8bda4d6fcbafe5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "excel_sheet = pd.ExcelFile(\"../Data/Raw/Ops_Overview_Data_File.xlsx\")\n",
    "# List all sheet names\n",
    "print(excel_sheet.sheet_names)"
   ],
   "id": "bdbbec9e71600702",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = None\n",
    "df = pd.read_excel(\"../Data/Raw/Ops_Overview_Data_File.xlsx\", sheet_name=\"Mortgage Servicing\")\n",
    "df.fillna(0, inplace=True)\n",
    "df[\"ONSHORE\"] = df[['ONSHORE TEAMMATE', 'ONSHORE CW', 'Est. Size- ONSHORE ']].sum(axis=1)\n",
    "df[\"OFFSHORE\"] = df[[\"Est. Size- OFFSHORE\"]]\n",
    "df.head(2)"
   ],
   "id": "c949a9c6df7fa20d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "\n",
    "sheet_name = \"Mortgage Servicing\"\n",
    "\n",
    "async def run_queries(row):\n",
    "    process   = row[\"Function / Process Name\"]\n",
    "    onshore   = row[\"ONSHORE\"]\n",
    "    offshore  = row[\"OFFSHORE\"]\n",
    "\n",
    "     # Build the two prompts\n",
    "    onshore_query = (\n",
    "        f\"What is the 5-year cumulative percentage change that Generative AI will have \"\n",
    "        f\"on the following process: {process} within the following Line of Business (LoB): \"\n",
    "        f\"{sheet_name}? Keep in mind that the bank's current onshore capacity is {onshore}\"\n",
    "    )\n",
    "    offshore_query = (\n",
    "        f\"What is the 5-year cumulative percentage change that Generative AI will have \"\n",
    "        f\"on the following process: {process} within the following Line of Business (LoB): \"\n",
    "        f\"{sheet_name}? Keep in mind that the bank's current offshore capacity is {offshore}\"\n",
    "    )\n",
    "    # Fire both queries concurrently\n",
    "    with trace(sheet_name):\n",
    "        on_task  = asyncio.create_task(Runner.run(q_a_agent, onshore_query, max_turns=100))\n",
    "        off_task = asyncio.create_task(Runner.run(q_a_agent, offshore_query, max_turns=100))\n",
    "    on, off  = await asyncio.gather(on_task, off_task)\n",
    "\n",
    "    return {\n",
    "        # ---------- On-shore ----------\n",
    "        \"Onshore_High_Scenario_Vectors\":    on.final_output.high_scenario,\n",
    "        \"Onshore_Medium_Scenario_Vectors\":  on.final_output.medium_scenario,\n",
    "        \"Onshore_Low_Scenario_Vectors\":     on.final_output.low_scenario,\n",
    "        \"Onshore_High_Scenario_Reasoning\":  on.final_output.high_scenario_reasoning,\n",
    "        \"Onshore_Medium_Scenario_Reasoning\":on.final_output.medium_scenario_reasoning,\n",
    "        \"Onshore_Low_Scenario_Reasoning\":   on.final_output.low_scenario_reasoning,\n",
    "        \"Onshore_CourseWork\":               on.final_output.online_coursework,\n",
    "        # ---------- Off-shore ----------\n",
    "        \"Offshore_High_Scenario_Vectors\":    off.final_output.high_scenario,\n",
    "        \"Offshore_Medium_Scenario_Vectors\":  off.final_output.medium_scenario,\n",
    "        \"Offshore_Low_Scenario_Vectors\":     off.final_output.low_scenario,\n",
    "        \"Offshore_High_Scenario_Reasoning\":  off.final_output.high_scenario_reasoning,\n",
    "        \"Offshore_Medium_Scenario_Reasoning\":off.final_output.medium_scenario_reasoning,\n",
    "        \"Offshore_Low_Scenario_Reasoning\":   off.final_output.low_scenario_reasoning,\n",
    "        \"Offshore_CourseWork\":               off.final_output.online_coursework,\n",
    "    }\n",
    "\n",
    "async def main():\n",
    "    coros = [run_queries(row) for _, row in df.iterrows()]\n",
    "    results = await asyncio.gather(*coros)                       #  ◀️ massive fan-out\n",
    "    df_out = pd.concat([df, pd.DataFrame(results)], axis=1)\n",
    "    return df_out\n",
    "\n",
    "df = await main()\n",
    "df.to_excel(\"../Data/Intermediate/Ops_Overview_Data_File_Processed.xlsx\", sheet_name=sheet_name, index=False)# ✔️ Jupyter’s loop drives it\n",
    "df.head()\n"
   ],
   "id": "17b2f3320b8c4a3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f298b716012a499b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
