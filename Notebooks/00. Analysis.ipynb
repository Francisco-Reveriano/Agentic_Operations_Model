{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "from agents import Runner, agent, trace, set_trace_processors, Agent, ModelSettings\n",
    "from weave.integrations.openai_agents.openai_agents import WeaveTracingProcessor\n",
    "import asyncio\n",
    "from typing import Literal, List, Annotated\n",
    "import weave\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field, conlist\n",
    "from IPython.display import display, Markdown, HTML, Image\n",
    "load_dotenv()\n",
    "# Import Necessary Libraries\n",
    "from src.Tools.Agentic_Calculator_Tool import Agentic_Calculator_Tool\n",
    "from src.Tools.PerplexitySECSonarPro_Tool import PerplexitySECSonarPro_Tool\n",
    "from src.Tools.Search_Tool import Search_Tool\n",
    "from src.Tools.OpenAIDeepResearch_Tool import OpenAIDeepResearch_Tool\n",
    "# Import Weave and Biases\n",
    "weave.init(\"Operation Model\")\n",
    "set_trace_processors([WeaveTracingProcessor()])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analysis Q&A Format",
   "id": "b9ab446cad67964b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ANALYSIS_QA_PROMPT = '''\n",
    "System= You are a Generative AI analyst that provides scenarios output.\n",
    "\n",
    "# Scenarios\n",
    "1. High Scenario assumes that Generative AI will severely impact the process.\n",
    "2. Medium Scenario assumes that Generative AI will have moderate process on the scenarios.\n",
    "3. Low Scenario assumes that Generative AI will have minimal impact on the scenarios.\n",
    "\n",
    "# Output Method\n",
    "1. Provide a detailed 5-year cumulative vector percentage change for each of the scenarios.\n",
    "\n",
    "# Instruction\n",
    "1. Thoroughly understand the process and information provided by the user.\n",
    "2. Use the <PerplexitySECSonarPro_Tool> to understand the detailed processes within a bank for the user original input.\n",
    "3. Use the <PerplexitySECSonarPro_Tool> to understand how the detailed process will be impacted by Generative AI in banks.\n",
    "4. Use the <Search_Tool> to search the internet for any additional information required.\n",
    "5. Use the <Agentic_Calculator_Tool> to evaluate the appropriateness of Generative AI for a specific business activity.\n",
    "6. Use the <OpenAIDeepResearch_Tool> to understand the impact of Generative AI on the business process.\n",
    "6. Provide a detailed 5-year cumulative vector percentage change for each of the scenarios.\n",
    "\n",
    "# Tool Description\n",
    "1. <PerplexitySECSonarPro_Tool>: Provides research capabilities for Security Exchange Commission (SEC) fillings.\n",
    "2. <Agentic_Calculator_Tool>: Provides a tool for evaluating the appropriateness of Generative AI for a specific business activity.\n",
    "3. <Search_Tool>: Provides a tool for searching for information on a given topic.\n",
    "4. <OpenAIDeepResearch_Tool>: OpenAIDeepResearch_Tool provides research capabilities for modeling how Generative AI will impact the business process in the next 5-years.\n",
    "'''\n",
    "\n",
    "class Agentic_Calculator_Tool_Output(BaseModel):\n",
    "    high_scenario: conlist(float, min_length=5, max_length=5)\n",
    "    \"High-scenario cumulative vector percentage change\"\n",
    "    medium_scenario: conlist(float, min_length=5, max_length=5)\n",
    "    \"Medium-scenario cumulative vector percentage change\"\n",
    "    low_scenario: conlist(float, min_length=5, max_length=5)\n",
    "    \"Low-scenario cumulative vector percentage change\"\n",
    "    high_scenario_reasoning: str\n",
    "    \"Provide a detailed reasoning chain of thought for the high-scenario cumulative vector percentage change\"\n",
    "    medium_scenario_reasoning: str\n",
    "    \"Provide a detailed reasoning chain of thought for the medium-scenario cumulative vector percentage change\"\n",
    "    low_scenario_reasoning: str\n",
    "    \"Provide a detailed reasoning chain of thought for the low-scenario cumulative vector percentage change\"\n",
    "    hallucination_score: Literal[\"Low\", \"Medium\", \"High\"]\n",
    "    \"Provide a score of the response quality. Low = Low hallucination risk, Medium = Medium hallucination risk, High = High hallucination risk\"\n",
    "\n",
    "q_a_agent = Agent(\n",
    "    name=\"q_a_agent\",\n",
    "    instructions=ANALYSIS_QA_PROMPT,\n",
    "    output_type=Agentic_Calculator_Tool_Output,\n",
    "    model=os.getenv(\"LLM_MODEL\"),\n",
    "    model_settings=ModelSettings(reasoning={\"effort\": \"high\"}),\n",
    "    tools=[\n",
    "            PerplexitySECSonarPro_Tool.as_tool(\n",
    "                tool_name=\"PerplexitySECSonarPro_Tool\",\n",
    "                tool_description=\"PerplexitySECSonarPro_Tool provides research capabilities for Security Exchange Commission (SEC) fillings.\"\n",
    "    ),\n",
    "           Agentic_Calculator_Tool.as_tool(\n",
    "               tool_name=\"Agentic_Calculator_Tool\",\n",
    "               tool_description=\"Agentic_Calculator_Tool provides a tool for evaluating the appropriateness of Generative AI for a specific business activity.\"\n",
    "           ),\n",
    "           Search_Tool.as_tool(\n",
    "               tool_name=\"Search_Tool\",\n",
    "               tool_description=\"Search_Tool provides a tool for searching for information on a given topic.\"\n",
    "           ),\n",
    "        OpenAIDeepResearch_Tool.as_tool(\n",
    "            tool_name=\"OpenAIDeepResearch_Tool\",\n",
    "            tool_description=\"OpenAIDeepResearch_Tool provides research capabilities for modeling how Generative AI will impact the business process in the next 5-years.\"\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "response = await Runner.run(q_a_agent, \"Mortgage Services in Load Admin\")"
   ],
   "id": "46fd93622d94d0fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "response.final_output",
   "id": "78a728d15d43dfe9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
