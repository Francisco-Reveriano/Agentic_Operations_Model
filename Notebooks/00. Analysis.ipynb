{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-08T23:54:52.947471Z",
     "start_time": "2025-08-08T23:54:44.120166Z"
    }
   },
   "source": [
    "import os\n",
    "from agents import Runner, agent, trace, set_trace_processors, Agent, ModelSettings\n",
    "from weave.integrations.openai_agents.openai_agents import WeaveTracingProcessor\n",
    "import asyncio\n",
    "from typing import Literal, List, Annotated\n",
    "import weave\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field, conlist\n",
    "from IPython.display import display, Markdown, HTML, Image\n",
    "load_dotenv()\n",
    "# Import Necessary Libraries\n",
    "from src.Tools.Agentic_Calculator_Tool import Agentic_Calculator_Tool\n",
    "from src.Tools.PerplexitySECSonarPro_Tool import PerplexitySECSonarPro_Tool\n",
    "from src.Tools.Search_Tool import Search_Tool\n",
    "from src.Tools.OpenAIDeepResearch_Tool import OpenAIDeepResearch_Tool\n",
    "# Import Weave and Biases\n",
    "weave.init(\"Operation Model\")\n",
    "set_trace_processors([WeaveTracingProcessor()])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m\u001B[1mweave\u001B[0m: Logged in as Weights & Biases user: francisco-reveriano-1.\n",
      "\u001B[36m\u001B[1mweave\u001B[0m: View Weave data at https://wandb.ai/francisco-reveriano-1-mckinsey-company/operation-model/weave\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analysis Q&A Format",
   "id": "b9ab446cad67964b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T00:25:40.892829Z",
     "start_time": "2025-08-08T23:54:52.956443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ANALYSIS_QA_PROMPT = '''\n",
    "System= You are a Generative AI analyst that provides scenarios output.\n",
    "\n",
    "# Scenarios\n",
    "1. High Scenario assumes that Generative AI will severely impact the process.\n",
    "2. Medium Scenario assumes that Generative AI will have moderate process on the scenarios.\n",
    "3. Low Scenario assumes that Generative AI will have minimal impact on the scenarios.\n",
    "\n",
    "# Output Method\n",
    "1. Provide a detailed 5-year cumulative vector percentage change for each of the scenarios.\n",
    "\n",
    "# Instruction\n",
    "1. Thoroughly understand the process and information provided by the user.\n",
    "2. Use the <PerplexitySECSonarPro_Tool> to understand the detailed processes within a bank for the user original input.\n",
    "3. Use the <PerplexitySECSonarPro_Tool> to understand how the detailed process will be impacted by Generative AI in banks.\n",
    "4. Use the <Search_Tool> to search the internet for any additional information required.\n",
    "5. Use the <Agentic_Calculator_Tool> to evaluate the appropriateness of Generative AI for a specific business activity.\n",
    "6. Use the <OpenAIDeepResearch_Tool> to understand the impact of Generative AI on the business process.\n",
    "6. Provide a detailed 5-year cumulative vector percentage change for each of the scenarios.\n",
    "\n",
    "# Tool Description\n",
    "1. <PerplexitySECSonarPro_Tool>: Provides research capabilities for Security Exchange Commission (SEC) fillings.\n",
    "2. <Agentic_Calculator_Tool>: Provides a tool for evaluating the appropriateness of Generative AI for a specific business activity.\n",
    "3. <Search_Tool>: Provides a tool for searching for information on a given topic.\n",
    "4. <OpenAIDeepResearch_Tool>: OpenAIDeepResearch_Tool provides research capabilities for modeling how Generative AI will impact the business process in the next 5-years.\n",
    "'''\n",
    "\n",
    "class Agentic_Calculator_Tool_Output(BaseModel):\n",
    "    high_scenario: conlist(float, min_length=5, max_length=5)\n",
    "    \"High-scenario cumulative vector percentage change\"\n",
    "    medium_scenario: conlist(float, min_length=5, max_length=5)\n",
    "    \"Medium-scenario cumulative vector percentage change\"\n",
    "    low_scenario: conlist(float, min_length=5, max_length=5)\n",
    "    \"Low-scenario cumulative vector percentage change\"\n",
    "    high_scenario_reasoning: str\n",
    "    \"Provide a detailed reasoning chain of thought for the high-scenario cumulative vector percentage change\"\n",
    "    medium_scenario_reasoning: str\n",
    "    \"Provide a detailed reasoning chain of thought for the medium-scenario cumulative vector percentage change\"\n",
    "    low_scenario_reasoning: str\n",
    "    \"Provide a detailed reasoning chain of thought for the low-scenario cumulative vector percentage change\"\n",
    "    hallucination_score: Literal[\"Low\", \"Medium\", \"High\"]\n",
    "    \"Provide a score of the response quality. Low = Low hallucination risk, Medium = Medium hallucination risk, High = High hallucination risk\"\n",
    "\n",
    "q_a_agent = Agent(\n",
    "    name=\"q_a_agent\",\n",
    "    instructions=ANALYSIS_QA_PROMPT,\n",
    "    output_type=Agentic_Calculator_Tool_Output,\n",
    "    model=os.getenv(\"LLM_MODEL\"),\n",
    "    model_settings=ModelSettings(reasoning={\"effort\": \"high\"}),\n",
    "    tools=[\n",
    "            PerplexitySECSonarPro_Tool.as_tool(\n",
    "                tool_name=\"PerplexitySECSonarPro_Tool\",\n",
    "                tool_description=\"PerplexitySECSonarPro_Tool provides research capabilities for Security Exchange Commission (SEC) fillings.\"\n",
    "    ),\n",
    "           Agentic_Calculator_Tool.as_tool(\n",
    "               tool_name=\"Agentic_Calculator_Tool\",\n",
    "               tool_description=\"Agentic_Calculator_Tool provides a tool for evaluating the appropriateness of Generative AI for a specific business activity.\"\n",
    "           ),\n",
    "           Search_Tool.as_tool(\n",
    "               tool_name=\"Search_Tool\",\n",
    "               tool_description=\"Search_Tool provides a tool for searching for information on a given topic.\"\n",
    "           ),\n",
    "        OpenAIDeepResearch_Tool.as_tool(\n",
    "            tool_name=\"OpenAIDeepResearch_Tool\",\n",
    "            tool_description=\"OpenAIDeepResearch_Tool provides research capabilities for modeling how Generative AI will impact the business process in the next 5-years.\"\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "response = await Runner.run(q_a_agent, \"Mortgage Services in Load Admin\")"
   ],
   "id": "46fd93622d94d0fc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m\u001B[1mweave\u001B[0m: üç© https://wandb.ai/francisco-reveriano-1-mckinsey-company/operation-model/r/call/01988c1b-dca5-7331-ac8c-99a349782cc7\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T00:25:40.951407Z",
     "start_time": "2025-08-09T00:25:40.947597Z"
    }
   },
   "cell_type": "code",
   "source": "response.final_output",
   "id": "78a728d15d43dfe9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agentic_Calculator_Tool_Output(high_scenario=[6.0, 14.0, 23.0, 31.0, 36.0], medium_scenario=[3.0, 8.0, 15.0, 21.0, 26.0], low_scenario=[1.0, 3.0, 5.0, 7.0, 8.0], high_scenario_reasoning='Definition of vector: Cumulative percentage reduction in overall mortgage servicing cost-to-serve per loan versus a 2024 baseline, by year over a 5-year horizon (2025‚Äì2029). Assumptions: aggressive GenAI adoption, deep integration with MSP/servicing cores (e.g., MSP/Black Knight, Sagent), rigorous model risk management (SR 11-7), and human-in-the-loop for borrower-facing outputs. Drivers by function: - Servicing onboarding/boarding and transfers: document ingestion/classification, data validation, and exception summarization reduce manual touches and transfer defects; cycle time down ~30‚Äì45% by Y5; fewer recon breaks. - Payment processing & cash management: AI triage of exception queues, misapplied payment explanations, and reconciliation suggestions reduce AHT and rework; exception backlog down ~40‚Äì60% by Y5. - Escrow administration: deterministic escrow math remains system-of-record; GenAI explains variances, drafts borrower notices, and powers self-service; call deflection 50‚Äì70% by Y5, first-contact resolution improves. - Investor reporting & remittances: narrative generation with evidence packs, RAG to investor guides (GSEs/GNMA/PLS), and automated QC reduce late/defect rates; rework down ~40‚Äì60% by Y5. - Default management: intelligent triage, tailored outreach scripts, and document prep improve cure rates by ~5‚Äì8 pp and shorten loss-mit timelines 15‚Äì25% by Y5; legal comms stay templated and reviewed. - Customer service/call center: agent-assist and borrower chat deflect majority of FAQs; AHT down ~20‚Äì35%, NPS +8‚Äì12 points by Y5. - QC/QA, compliance, audit, vendor risk: AI assembles evidence, runs checklist validations, drafts change-mgmt artifacts with citations; QA error rates down ~50‚Äì65% by Y5. Guardrails: strict RAG with citations, template/slot-based outbound comms, auditable logs, PII minimization, fairness/UDAAP checkers, and mandatory reviewer sign-off. Resulting cumulative cost-to-serve reduction vector reflects stacked savings across the above, yielding [6, 14, 23, 31, 36]%.', medium_scenario_reasoning='Definition of vector as above. Assumptions: targeted GenAI where risk is lower; integration primarily via vendor-delivered features from core servicing platforms; conservative compliance posture; human review on all borrower communications and investor narratives. Scope emphasis: policy/procedure copilots, agent-assist in call centers, escrow explanation drafting with reviewer, investor narrative drafting, and QC evidence assembly. Expected effects by function by Y5: - Onboarding/transfers: 15‚Äì25% faster cycles; fewer manual keying errors. - Payment exceptions: 20‚Äì35% reduction in backlog and AHT through prioritization and suggested resolutions. - Escrow: 25‚Äì40% call deflection on FAQs; clearer explanations reduce repeat contacts. - Investor reporting: 20‚Äì35% less rework via templated narrative drafting and RAG to guides. - Default: proactive triage modestly improves engagement; cure +2‚Äì4 pp; timeline improvements 8‚Äì15%. - QC/QA/compliance: 25‚Äì40% reduction in documentation prep time; error detection improved but with reviewer gates. Risks and controls: model monitoring, rejection when confidence/citation coverage is low, privacy controls, and vendor MRM. Stacked savings produce cumulative cost-to-serve reduction vector [3, 8, 15, 21, 26]%.', low_scenario_reasoning='Definition of vector as above. Assumptions: limited pilots; GenAI confined to internal knowledge search, drafting aids for internal memos, and light agent-assist; minimal integration with MSP; strict compliance gating slows expansion. Effects by Y5: - Onboarding/transfers: small gains from checklists and doc summaries; cycle time down 5‚Äì10%. - Payment exceptions: suggested notes and categorization shave modest AHT; 10‚Äì15% improvement. - Escrow: internal explanation drafting reduces handle time but little self-service/deflection; 10‚Äì15% reduction in repeat calls on targeted topics. - Investor reporting: editorial assistance only; 10‚Äì15% rework reduction. - Default: communications templating improves consistency; minimal impact on cure (<1‚Äì2 pp). - QC/QA/compliance: faster evidence gathering and policy lookup; 10‚Äì15% error-rate reduction on reviewed items. Controls: human-in-the-loop on all outputs; no autonomous borrower-facing messaging; privacy and MRM fully enforced. Net savings are modest, yielding cumulative cost-to-serve reduction vector [1, 3, 5, 7, 8]%.', hallucination_score='Medium')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
